{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T21:22:44.493048Z",
     "start_time": "2024-05-08T21:22:44.480476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"http://127.0.0.1:8000/get-relevant-data/10029\")\n",
    "result = response.json()"
   ],
   "id": "72546ea6390b0d4b",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T21:22:46.525099Z",
     "start_time": "2024-05-08T21:22:46.505126Z"
    }
   },
   "cell_type": "code",
   "source": "result",
   "id": "31162074d034c768",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detail': 'Not Found'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T04:36:29.525023Z",
     "start_time": "2024-05-08T04:36:25.253696Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "6dad2d364b44d76c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T04:36:30.412718Z",
     "start_time": "2024-05-08T04:36:30.341776Z"
    }
   },
   "cell_type": "code",
   "source": "patients_df = pd.read_csv('../mimic-iii-clinical-database-demo-1.4\\PATIENTS.csv')\n",
   "id": "592fda95a9aa24c4",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T04:36:40.895827Z",
     "start_time": "2024-05-08T04:36:40.863913Z"
    }
   },
   "cell_type": "code",
   "source": "patients_df",
   "id": "7253622d93876efd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    row_id  subject_id gender                  dob                  dod  \\\n",
       "0     9467       10006      F  2094-03-05 00:00:00  2165-08-12 00:00:00   \n",
       "1     9472       10011      F  2090-06-05 00:00:00  2126-08-28 00:00:00   \n",
       "2     9474       10013      F  2038-09-03 00:00:00  2125-10-07 00:00:00   \n",
       "3     9478       10017      F  2075-09-21 00:00:00  2152-09-12 00:00:00   \n",
       "4     9479       10019      M  2114-06-20 00:00:00  2163-05-15 00:00:00   \n",
       "..     ...         ...    ...                  ...                  ...   \n",
       "95   31838       44083      M  2057-11-15 00:00:00  2114-02-20 00:00:00   \n",
       "96   31853       44154      M  1878-05-14 00:00:00  2178-05-15 00:00:00   \n",
       "97   31867       44212      F  2078-06-16 00:00:00  2124-01-29 00:00:00   \n",
       "98   31870       44222      M  2107-06-27 00:00:00  2182-08-03 00:00:00   \n",
       "99   31872       44228      F  2112-10-22 00:00:00  2171-04-14 00:00:00   \n",
       "\n",
       "               dod_hosp              dod_ssn  expire_flag  \n",
       "0   2165-08-12 00:00:00  2165-08-12 00:00:00            1  \n",
       "1   2126-08-28 00:00:00                  NaN            1  \n",
       "2   2125-10-07 00:00:00  2125-10-07 00:00:00            1  \n",
       "3                   NaN  2152-09-12 00:00:00            1  \n",
       "4   2163-05-15 00:00:00  2163-05-15 00:00:00            1  \n",
       "..                  ...                  ...          ...  \n",
       "95  2114-02-20 00:00:00  2114-02-20 00:00:00            1  \n",
       "96  2178-05-15 00:00:00  2178-05-15 00:00:00            1  \n",
       "97                  NaN  2124-01-29 00:00:00            1  \n",
       "98  2182-08-03 00:00:00                  NaN            1  \n",
       "99  2171-04-14 00:00:00                  NaN            1  \n",
       "\n",
       "[100 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>dod</th>\n",
       "      <th>dod_hosp</th>\n",
       "      <th>dod_ssn</th>\n",
       "      <th>expire_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9467</td>\n",
       "      <td>10006</td>\n",
       "      <td>F</td>\n",
       "      <td>2094-03-05 00:00:00</td>\n",
       "      <td>2165-08-12 00:00:00</td>\n",
       "      <td>2165-08-12 00:00:00</td>\n",
       "      <td>2165-08-12 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9472</td>\n",
       "      <td>10011</td>\n",
       "      <td>F</td>\n",
       "      <td>2090-06-05 00:00:00</td>\n",
       "      <td>2126-08-28 00:00:00</td>\n",
       "      <td>2126-08-28 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9474</td>\n",
       "      <td>10013</td>\n",
       "      <td>F</td>\n",
       "      <td>2038-09-03 00:00:00</td>\n",
       "      <td>2125-10-07 00:00:00</td>\n",
       "      <td>2125-10-07 00:00:00</td>\n",
       "      <td>2125-10-07 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9478</td>\n",
       "      <td>10017</td>\n",
       "      <td>F</td>\n",
       "      <td>2075-09-21 00:00:00</td>\n",
       "      <td>2152-09-12 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2152-09-12 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9479</td>\n",
       "      <td>10019</td>\n",
       "      <td>M</td>\n",
       "      <td>2114-06-20 00:00:00</td>\n",
       "      <td>2163-05-15 00:00:00</td>\n",
       "      <td>2163-05-15 00:00:00</td>\n",
       "      <td>2163-05-15 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>31838</td>\n",
       "      <td>44083</td>\n",
       "      <td>M</td>\n",
       "      <td>2057-11-15 00:00:00</td>\n",
       "      <td>2114-02-20 00:00:00</td>\n",
       "      <td>2114-02-20 00:00:00</td>\n",
       "      <td>2114-02-20 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>31853</td>\n",
       "      <td>44154</td>\n",
       "      <td>M</td>\n",
       "      <td>1878-05-14 00:00:00</td>\n",
       "      <td>2178-05-15 00:00:00</td>\n",
       "      <td>2178-05-15 00:00:00</td>\n",
       "      <td>2178-05-15 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>31867</td>\n",
       "      <td>44212</td>\n",
       "      <td>F</td>\n",
       "      <td>2078-06-16 00:00:00</td>\n",
       "      <td>2124-01-29 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2124-01-29 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>31870</td>\n",
       "      <td>44222</td>\n",
       "      <td>M</td>\n",
       "      <td>2107-06-27 00:00:00</td>\n",
       "      <td>2182-08-03 00:00:00</td>\n",
       "      <td>2182-08-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>31872</td>\n",
       "      <td>44228</td>\n",
       "      <td>F</td>\n",
       "      <td>2112-10-22 00:00:00</td>\n",
       "      <td>2171-04-14 00:00:00</td>\n",
       "      <td>2171-04-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T04:48:55.784743Z",
     "start_time": "2024-05-08T04:45:34.748074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "data = {}\n",
    "database_folder = '../mimic-iii-clinical-database-demo-1.4'\n",
    "patients_df = pd.read_csv('../mimic-iii-clinical-database-demo-1.4\\PATIENTS.csv')\n",
    "\n",
    "for subject_id in patients_df['subject_id']:\n",
    "    data[subject_id] = {}\n",
    "    for file_name in os.listdir(database_folder):\n",
    "        # Skip PATIENTS.csv file\n",
    "        if file_name == 'PATIENTS.csv' or file_name =='CAREGIVERS.csv':\n",
    "            continue\n",
    "        if file_name.startswith('D_'):\n",
    "            continue\n",
    "\n",
    "\n",
    "        if file_name.endswith('.csv'):\n",
    "            table_name = file_name.split('.')[0]\n",
    "            df = pd.read_csv(os.path.join(database_folder, file_name),low_memory=False)\n",
    "            data[subject_id][table_name] = df[df['subject_id'] == subject_id].to_dict(orient='records')\n"
   ],
   "id": "cb1a0210bdcce43b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T04:53:54.810585Z",
     "start_time": "2024-05-08T04:53:54.791091Z"
    }
   },
   "cell_type": "code",
   "source": "patients_df['subject_id']",
   "id": "d4254fbe0fa3e5ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     10006\n",
       "1     10011\n",
       "2     10013\n",
       "3     10017\n",
       "4     10019\n",
       "      ...  \n",
       "95    44083\n",
       "96    44154\n",
       "97    44212\n",
       "98    44222\n",
       "99    44228\n",
       "Name: subject_id, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T21:52:36.563488Z",
     "start_time": "2024-05-08T21:52:36.548478Z"
    }
   },
   "cell_type": "code",
   "source": "data[10006].keys()",
   "id": "4a3628dd010c3ecc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ADMISSIONS', 'CALLOUT', 'CHARTEVENTS', 'CPTEVENTS', 'DATETIMEEVENTS', 'DIAGNOSES_ICD', 'DRGCODES', 'ICUSTAYS', 'INPUTEVENTS_CV', 'INPUTEVENTS_MV', 'LABEVENTS', 'MICROBIOLOGYEVENTS', 'OUTPUTEVENTS', 'PRESCRIPTIONS', 'PROCEDUREEVENTS_MV', 'PROCEDURES_ICD', 'SERVICES', 'TRANSFERS'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T22:09:35.991197Z",
     "start_time": "2024-05-08T22:09:35.941318Z"
    }
   },
   "cell_type": "code",
   "source": "list(data[10006].keys())",
   "id": "1c4cf905041e7b88",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADMISSIONS',\n",
       " 'CALLOUT',\n",
       " 'CHARTEVENTS',\n",
       " 'CPTEVENTS',\n",
       " 'DATETIMEEVENTS',\n",
       " 'DIAGNOSES_ICD',\n",
       " 'DRGCODES',\n",
       " 'ICUSTAYS',\n",
       " 'INPUTEVENTS_CV',\n",
       " 'INPUTEVENTS_MV',\n",
       " 'LABEVENTS',\n",
       " 'MICROBIOLOGYEVENTS',\n",
       " 'OUTPUTEVENTS',\n",
       " 'PRESCRIPTIONS',\n",
       " 'PROCEDUREEVENTS_MV',\n",
       " 'PROCEDURES_ICD',\n",
       " 'SERVICES',\n",
       " 'TRANSFERS']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T12:05:15.883956Z",
     "start_time": "2024-05-13T12:05:13.303122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Float, text\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create a SQLAlchemy engine with an in-memory SQLite database\n",
    "engine = create_engine(\"sqlite:///C:\\\\Users\\\\mtalh\\\\OneDrive\\\\Desktop\\\\ML\\\\Xavor\\\\bootcamp\\\\langserve_medicalmind\\\\mimic3.db\")\n",
    "engine.connect()"
   ],
   "id": "6633c85d05d2a1ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x2477bf64550>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Graphs",
   "id": "6cb024d73b58f2d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T09:51:36.018842Z",
     "start_time": "2024-05-21T09:51:26.627388Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install langchain_openai",
   "id": "736f04451f029972",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from langchain_openai) (0.1.48)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from langchain_openai) (1.25.0)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (0.1.52)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (2.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.4.28)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain_openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.46->langchain_openai) (3.10.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_openai) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mtalh\\onedrive\\desktop\\ml\\conda\\env\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.24.0->langchain_openai) (0.4.6)\n",
      "Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
      "Downloading tiktoken-0.7.0-cp310-cp310-win_amd64.whl (798 kB)\n",
      "   ---------------------------------------- 0.0/798.9 kB ? eta -:--:--\n",
      "   - ------------------------------------- 30.7/798.9 kB 660.6 kB/s eta 0:00:02\n",
      "   -- ------------------------------------ 61.4/798.9 kB 825.8 kB/s eta 0:00:01\n",
      "   --- ----------------------------------- 81.9/798.9 kB 657.6 kB/s eta 0:00:02\n",
      "   -------- ----------------------------- 174.1/798.9 kB 958.1 kB/s eta 0:00:01\n",
      "   --------- ---------------------------- 194.6/798.9 kB 985.7 kB/s eta 0:00:01\n",
      "   --------------- ------------------------ 307.2/798.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 450.6/798.9 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 491.5/798.9 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  798.7/798.9 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 798.9/798.9 kB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken, langchain_openai\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.6.0\n",
      "    Uninstalling tiktoken-0.6.0:\n",
      "      Successfully uninstalled tiktoken-0.6.0\n",
      "Successfully installed langchain_openai-0.1.7 tiktoken-0.7.0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T09:51:47.603013Z",
     "start_time": "2024-05-21T09:51:46.244941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    # Each worker node will be given a name and some tools.\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor"
   ],
   "id": "a4de16cdd0690341",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T09:51:53.690817Z",
     "start_time": "2024-05-21T09:51:53.678509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ],
   "id": "3a42461e9155f9d5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T09:55:23.183482Z",
     "start_time": "2024-05-21T09:55:22.808060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "members = [\"Database retriever\", \"Researcher\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers:  {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = [\"FINISH\"] + members\n",
    "# Using openai function calling can make output parsing easier for us\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\": {\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\": {\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given the conversation above, who should act next?\"\n",
    "            \" Or should we FINISH? Select one of: {options}\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ],
   "id": "36cf83fefb945c96",
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 45\u001B[0m\n\u001B[0;32m     16\u001B[0m function_def \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroute\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSelect the next role.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     31\u001B[0m     },\n\u001B[0;32m     32\u001B[0m }\n\u001B[0;32m     33\u001B[0m prompt \u001B[38;5;241m=\u001B[39m ChatPromptTemplate\u001B[38;5;241m.\u001B[39mfrom_messages(\n\u001B[0;32m     34\u001B[0m     [\n\u001B[0;32m     35\u001B[0m         (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m\"\u001B[39m, system_prompt),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     42\u001B[0m     ]\n\u001B[0;32m     43\u001B[0m )\u001B[38;5;241m.\u001B[39mpartial(options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mstr\u001B[39m(options), members\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(members))\n\u001B[1;32m---> 45\u001B[0m llm \u001B[38;5;241m=\u001B[39m \u001B[43mChatOpenAI\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpt-3.5-turbo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m supervisor_chain \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     48\u001B[0m     prompt\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;241m|\u001B[39m llm\u001B[38;5;241m.\u001B[39mbind_functions(functions\u001B[38;5;241m=\u001B[39m[function_def], function_call\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mroute\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;241m|\u001B[39m JsonOutputFunctionsParser()\n\u001B[0;32m     51\u001B[0m )\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\ML\\conda\\env\\lib\\site-packages\\langchain_core\\load\\serializable.py:120\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 120\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lc_kwargs \u001B[38;5;241m=\u001B[39m kwargs\n",
      "File \u001B[1;32m~\\OneDrive\\Desktop\\ML\\conda\\env\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[1;34m(__pydantic_self__, **data)\u001B[0m\n\u001B[0;32m    339\u001B[0m values, fields_set, validation_error \u001B[38;5;241m=\u001B[39m validate_model(__pydantic_self__\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, data)\n\u001B[0;32m    340\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validation_error:\n\u001B[1;32m--> 341\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m validation_error\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    343\u001B[0m     object_setattr(__pydantic_self__, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__dict__\u001B[39m\u001B[38;5;124m'\u001B[39m, values)\n",
      "\u001B[1;31mValidationError\u001B[0m: 1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import operator\n",
    "from typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\n",
    "import functools\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "# The agent state is the input to each node in the graph\n",
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str\n",
    "\n",
    "\n",
    "research_agent = create_agent(llm, [tavily_tool], \"You are a web researcher.\")\n",
    "research_node = functools.partial(agent_node, agent=research_agent, name=\"Researcher\")\n",
    "\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION. PROCEED WITH CAUTION\n",
    "code_agent = create_agent(\n",
    "    llm,\n",
    "    [python_repl_tool],\n",
    "    \"You may generate safe python code to analyze data and generate charts using matplotlib.\",\n",
    ")\n",
    "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Researcher\", research_node)\n",
    "workflow.add_node(\"Coder\", code_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)"
   ],
   "id": "afd5babd1859dea7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
